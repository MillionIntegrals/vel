name: 'mujoco_a2c'


env:
  name: vel.rl.env.mujoco
  game: !param game = 'Reacher-v2'


vec_env:
  name: vel.rl.vecenv.dummy
  normalize_returns: true


model:
  name: vel.rl.policy.a2c

  entropy_coefficient: 0.0
  value_coefficient: 0.5
  gae_lambda: 0.95 # Generalized Advantage Estimator Lambda parameter
  discount_factor: 0.99 # Discount factor for the rewards

  net:
    name: vel.net.modular
    layers:
      - name: vel.net.layer.input.normalize_ewma
      - name: vel.net.layer.mlp
        hidden_layers: [64, 64]
        activation: 'tanh'
      - name: vel.net.layer.util.repeat
        times: 2 # Need to repeat output twice, for action and value heads


reinforcer:
  name: vel.rl.reinforcer.on_policy_iteration_reinforcer

  env_roller:
    name: vel.rl.env_roller.step_env_roller

  parallel_envs: 1 # How many environments to run in parallel
  number_of_steps: 2048 # How many environment steps go into a single batch
  batch_size: 2048 # How many samples can go into the model once


optimizer:
  name: vel.optimizer.adam
  lr: 3.0e-4
  epsilon: 1.0e-5
  max_grad_norm: 0.5


commands:
  train:
    name: vel.rl.command.rl_train_command
    total_frames: 1.0e6
    batches_per_epoch: 1

  record:
    name: vel.rl.command.record_movie_command
    takes: 10
    videoname: 'reacher_vid_{:04}.avi'
