name: 'atari_trpo'


env:
  name: vel.rl.env.classic_atari
  game: !param game = 'BreakoutNoFrameskip-v4'


vec_env:
  name: vel.rl.vecenv.shared_mem
  frame_history: 4  # How many stacked frames go into a single observation


model:
  name: vel.rl.policy.trpo

  max_kl: 0.001
  cg_iters: 10
  line_search_iters: 10
  improvement_acceptance_ratio: 0.1
  cg_damping: 0.001
  vf_iters: 3
  entropy_coefficient: 0.1
  discount_factor: 0.99

  gae_lambda: 1.00 # Generalized Advantage Estimator Lambda parameter

  policy_net:
    name: vel.net.modular
    layers:
      - name: vel.net.layer.input.image_to_tensor
        size: [84, 84, 4] # Number of channels is frame history
      - name: vel.rl.layer.nature_cnn_small

  value_net:
    name: vel.net.modular
    layers:
      - name: vel.net.layer.input.image_to_tensor
        size: [84, 84, 4] # Number of channels is frame history
      - name: vel.rl.layer.nature_cnn_small


reinforcer:
  name: vel.rl.reinforcer.on_policy_iteration_reinforcer

  env_roller:
    name: vel.rl.env_roller.step_env_roller

  # In openAI baselines they rollout single env for 512 steps.
  # I roll out 16 envs for 32 steps in parallel
  parallel_envs: 16 # How many environments to run in parallel
  number_of_steps: 32 # How many environment steps go into a single batch
  batch_size: 512


optimizer:
  name: vel.optimizer.adam
  lr: 1.0e-4
  epsilon: 1.0e-3
#    max_grad_norm: 0.5


commands:
  train:
    name: vel.rl.command.rl_train_command
    total_frames: 1.1e7
    batches_per_epoch: 16

  record:
    name: vel.rl.command.record_movie_command
    takes: 10
    videoname: 'atari_trpo_vid_{:04}.avi'
    frame_history: 4
    sample_args:
      argmax_sampling: true

  evaluate:
    name: vel.rl.command.evaluate_env_command
    takes: 100
    frame_history: 4
    sample_args:
      argmax_sampling: true
